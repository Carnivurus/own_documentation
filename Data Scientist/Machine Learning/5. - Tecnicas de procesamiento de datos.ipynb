{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para Modelos de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobremuestreo\n",
    "\n",
    "El sobremuestreo, en el contexto del aprendizaje automático y especialmente en el manejo de conjuntos de datos desbalanceados, es una técnica que se utiliza para aumentar el número de muestras en la clase minoritaria (la clase menos representada) con el fin de equilibrar mejor la distribución de clases en el conjunto de datos.\n",
    "\n",
    "El sobremuestreo se realiza en varios pasos:\n",
    "- Dividir el conjunto de datos de entrenamiento en observaciones negativas y positivas;\n",
    "- Duplicar las observaciones positivas (las que tienen ocurrencias raras) varias veces;\n",
    "- Crear una nueva muestra de entrenamiento basada en los datos obtenidos;\n",
    "- Barajar los datos: preguntas idénticas que se suceden no ayudarán al entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.13688212927756654\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Importamos el conjunto de datos\n",
    "\n",
    "data = pd.read_csv('D:/Tripleten/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "# Definimos el objetivo y el los elementos para entrenar\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "\n",
    "# Dividimos el conjunto en training y validación\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# Declaramos una funcion para obtener el sobremuestreo del conjunto de entrenamiento\n",
    "# Separamos los elementos en los cuales su target tiene 0 y 1\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    # Concatenamos no sin antes exponenciar los resultados para tener un conjunto mas robusto.\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# Llamamos la funcion y recibimos dos variables\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n",
    "\n",
    "# Entrenamos nuestro modelo\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled,target_upsampled)\n",
    "\n",
    "#Predecimos y entregamos el resultado.\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submuestreo\n",
    "\n",
    "El submuestreo, es una técnica utilizada para abordar el desequilibrio de clases en un conjunto de datos, El submuestreo implica reducir el número de ejemplos de las clases mayoritarias para igualar el número de ejemplos de las clases minoritarias. Esto se hace típicamente seleccionando aleatoriamente una muestra de los ejemplos de las clases mayoritarias para que coincida con el número de ejemplos de las clases minoritarias.\n",
    "\n",
    "El submuestreo se realiza en varios pasos:\n",
    "- Dividir el conjunto de datos de entrenamiento en observaciones negativas y positivas;\n",
    "- Soltar al azar una parte de las observaciones negativas;\n",
    "- Crear una nueva muestra de entrenamiento basada en los datos obtenidos después de la caída;\n",
    "- Mezclar los datos. Asegúrate de que los datos positivos no sigan a los negativos: esto dificultará que los algoritmos aprendan.\n",
    "- Para descartar de forma aleatoria algunos de los elementos de la tabla, usa la función sample(). Esta toma frac (de fracción) y devuelve elementos aleatorios en cantidades tales que su fracción en la tabla inicial sea igual a frac.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "Algoritmo que crea datos nuevos,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Importing the modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Importing the library\n",
    "data = pd.read_csv('D:/Tripleten/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "#Defining a function \n",
    "def downsample(features, target, fraction):\n",
    "    '''This function will downsample the zeros in features and target, the will concatenate the results with the ones and will return a shuffle df'''\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    # Concatenating samples\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=0.1, random_state=12345)]+[features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=0.1, random_state=12345)]+[target_ones])\n",
    "\n",
    "    # shuffling the dataframes\n",
    "    features_downsampled =  shuffle(features_downsampled, random_state=12345)\n",
    "    target_downsampled = shuffle(target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "# Calling the function\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train, target_train, 0.1\n",
    ")\n",
    "\n",
    "model = LogisticRegression(random_state = 12345, solver= 'liblinear' )\n",
    "model.fit(features_downsampled,target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para estandarizar (Regresión y Clasificación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaler\n",
    "\n",
    "The Standard Scaler standardize the numeric values. Applies for classification and regression algorithms. Makes the númeric values to have a mean of '0' an standard deviation of '1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Agency    Agency Type Distribution Channel              Product Name  \\\n",
      "33312    EPX  Travel Agency               Online         Cancellation Plan   \n",
      "50154    EPX  Travel Agency               Online         Cancellation Plan   \n",
      "26729    EPX  Travel Agency               Online         Cancellation Plan   \n",
      "37842    EPX  Travel Agency               Online  2 way Comprehensive Plan   \n",
      "23588    EPX  Travel Agency               Online  2 way Comprehensive Plan   \n",
      "\n",
      "       Duration Destination  Net Sales  Commission (in value) Gender       Age  \n",
      "33312  0.243485       CHINA  -0.513068              -0.500631    NaN -0.283389  \n",
      "50154 -0.266879   SINGAPORE  -0.554403              -0.500631    NaN -0.283389  \n",
      "26729 -0.329555    MALAYSIA  -0.637074              -0.500631    NaN -0.709982  \n",
      "37842 -0.069896    THAILAND   0.065625              -0.500631    NaN -0.354488  \n",
      "23588 -0.374324    MALAYSIA  -0.430398              -0.500631    NaN -0.425587  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('D:/Tripleten/datasets/travel_insurance_us.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "numeric = ['Duration', 'Net Sales', 'Commission (in value)', 'Age']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "\n",
    "print(features_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Duration  Net Sales  Commission (in value)       Age  Agency_ART  \\\n",
      "33312  0.243485  -0.513068              -0.500631 -0.283389       False   \n",
      "50154 -0.266879  -0.554403              -0.500631 -0.283389       False   \n",
      "26729 -0.329555  -0.637074              -0.500631 -0.709982       False   \n",
      "37842 -0.069896   0.065625              -0.500631 -0.354488       False   \n",
      "23588 -0.374324  -0.430398              -0.500631 -0.425587       False   \n",
      "\n",
      "       Agency_C2B  Agency_CBH  Agency_CCR  Agency_CSR  Agency_CWT  ...  \\\n",
      "33312       False       False       False       False       False  ...   \n",
      "50154       False       False       False       False       False  ...   \n",
      "26729       False       False       False       False       False  ...   \n",
      "37842       False       False       False       False       False  ...   \n",
      "23588       False       False       False       False       False  ...   \n",
      "\n",
      "       Destination_URUGUAY  Destination_UZBEKISTAN  Destination_VANUATU  \\\n",
      "33312                False                   False                False   \n",
      "50154                False                   False                False   \n",
      "26729                False                   False                False   \n",
      "37842                False                   False                False   \n",
      "23588                False                   False                False   \n",
      "\n",
      "       Destination_VENEZUELA  Destination_VIET NAM  Destination_ZAMBIA  \\\n",
      "33312                  False                 False               False   \n",
      "50154                  False                 False               False   \n",
      "26729                  False                 False               False   \n",
      "37842                  False                 False               False   \n",
      "23588                  False                 False               False   \n",
      "\n",
      "       Destination_ZIMBABWE  Destination_nan  Gender_M  Gender_nan  \n",
      "33312                 False            False     False        True  \n",
      "50154                 False            False     False        True  \n",
      "26729                 False            False     False        True  \n",
      "37842                 False            False     False        True  \n",
      "23588                 False            False     False        True  \n",
      "\n",
      "[5 rows x 193 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importing the dataset\n",
    "data = pd.read_csv('D:/Tripleten/datasets/travel_insurance_us.csv')\n",
    "\n",
    "# Encoding categoric values into binaries\n",
    "data_ohe = pd.get_dummies(data, drop_first=True, dummy_na=True)\n",
    "\n",
    "features = data_ohe.drop(columns='Claim')\n",
    "target = data_ohe['Claim']\n",
    "\n",
    "# Creating a validation and training dataset\n",
    "x_train, x_val, y_train, y_val = train_test_split(features, target, test_size= 0.25, random_state=12345)\n",
    "\n",
    "# Extracting the columns with int and float values\n",
    "numeric = features.select_dtypes(include=['int','float']).columns\n",
    "\n",
    "# Escalating the numeric values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train[numeric])\n",
    "\n",
    "# Transforming and passing the values into the features and target\n",
    "x_train[numeric] = scaler.transform(x_train[numeric])\n",
    "x_val[numeric] = scaler.transform(x_val[numeric])\n",
    "\n",
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "50655    0\n",
      "50656    0\n",
      "50657    0\n",
      "50658    0\n",
      "50659    0\n",
      "Name: Claim, Length: 50660, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('D:/Tripleten/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "\n",
    "target_pred_constant = data['Claim'].replace(data['Claim'].values, 0)\n",
    "print(target_pred_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58431, 22)\n",
      "(19478, 22)\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importing Data sets\n",
    "data = pd.read_csv('/datasets/flights.csv')\n",
    "\n",
    "# Using OHE for categoric column 'Airlines'\n",
    "data_ohe = pd.get_dummies(data, drop_first= True)\n",
    "\n",
    "# Defining target and features\n",
    "target = data_ohe['Arrival Delay']\n",
    "features = data_ohe.drop(['Arrival Delay'], axis=1)\n",
    "\n",
    "# Slicing the dataset to receive a train and a valid dataset.\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# Defining the columns to be used in the scaler class\n",
    "numeric = features.select_dtypes(include=['int', 'float']).columns\n",
    "#numeric = ['Day', 'Day Of Week', 'Origin Airport Delay Rate',\n",
    "#       'Destination Airport Delay Rate', 'Scheduled Time', 'Distance',\n",
    "#       'Scheduled Departure Hour', 'Scheduled Departure Minute']\n",
    "\n",
    "# Using the StandardScaler class to transform the numeric values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
