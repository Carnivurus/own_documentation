{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo del Intervalo de Confianza\n",
    "Para construir un intervalo de confianza del 90% alrededor de la media poblacional, se utilizan los percentiles de la distribución normal estándar. Específicamente, se toman los valores correspondientes a los percentiles 5% y 95% (denotados como F(0.05) y F(0.95)), y se multiplican por el error estándar de la media para obtener los límites inferiores y superiores del intervalo de confianza.\n",
    "\n",
    "## Error Estándar de la Media (SEM)\n",
    "Es la desviación estándar de la distribución de las medias muestrales. Se calcula dividiendo la desviación estándar de la población por la raíz cuadrada del tamaño de la muestra. Cuanto mayor sea el tamaño de la muestra, menor será el error estándar y más precisa será la estimación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible simplificar el cálculo utilizando la distribución de Student scipy.stats.t. Tiene una función para el intervalo de confianza, interval(), que toma:\n",
    "\n",
    "- alpha: nivel de significación\n",
    "- df: número de grados de libertad (igual a n - 1)\n",
    "- loc (de localización): la distribución media igual a la estimación media. Para la muestra, se calcula del modo siguiente: sample.mean()\n",
    "- scale: el error estándar de la distribución igual a la estimación del error estándar. Se calcula de la siguiente manera: sample.sem()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "\n",
    "sample = pd.Series([\n",
    "    439, 518, 452, 505, 493, 470, 498, 442, 497, \n",
    "    423, 524, 442, 459, 452, 463, 488, 497, 500,\n",
    "    476, 501, 456, 425, 438, 435, 516, 453, 505, \n",
    "    441, 477, 469, 497, 502, 442, 449, 465, 429,\n",
    "    442, 472, 466, 431, 490, 475, 447, 435, 482, \n",
    "    434, 525, 510, 494, 493, 495, 499, 455, 464,\n",
    "    509, 432, 476, 438, 512, 423, 428, 499, 492, \n",
    "    493, 467, 493, 468, 420, 513, 427])\n",
    "\n",
    "print('Media:', sample.mean())\n",
    "\n",
    "confidence_interval = st.t.interval(0.95,df=sample.count()-1,loc=sample.mean(), scale= sample.sem())\n",
    "\n",
    "print('Intervalo de confianza del 95 %:', confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funcion interval es un método que utiliza la distribución t de Student para calcular el intervalo de confianza. Este método asume que los datos siguen una distribución t de Student y tiene en cuenta el tamaño de la muestra, lo que lo hace útil cuando el tamaño de la muestra es pequeño y/o la desviación estándar de la población es desconocida.\n",
    "\n",
    "La función sample.sem() se refiere al método para calcular el error estándar de la media (SEM) a partir de una muestra de datos. La SEM es una medida de cuánto varía la media muestral de una muestra a otra. Es especialmente útil cuando estamos tratando de estimar la precisión de la media muestral como una estimación de la media poblacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "El bootstrapping es una técnica de remuestreo que se utiliza en estadística para estimar la distribución de una estadística de interés (como la media, la mediana, la varianza, etc.) a partir de una muestra de datos. Esta técnica es particularmente útil cuando no se conocen las distribuciones teóricas de los datos o cuando se dispone de una muestra pequeña.\n",
    "\n",
    "El proceso básico del bootstrapping implica lo siguiente:\n",
    "\n",
    "- Tomar una muestra de datos con reemplazo de la muestra original. Esto significa que los elementos de la muestra original se pueden seleccionar más de una vez y también pueden no ser seleccionados en absoluto en la muestra de bootstrap resultante.\n",
    "- Calcular la estadística de interés (por ejemplo, la media, la mediana, etc.) para cada muestra de bootstrap generada en el paso anterior.\n",
    "- Repetir los pasos 1 y 2 muchas veces (generalmente miles de veces) para obtener una distribución empírica de la estadística de interés.\n",
    "- Utilizar esta distribución empírica para estimar intervalos de confianza, realizar pruebas de hipótesis u otros análisis estadísticos.\n",
    "\n",
    "El bootstrapping es una técnica poderosa y flexible que se puede aplicar a una amplia variedad de problemas en estadística y ciencia de datos. Permite obtener estimaciones precisas de la incertidumbre asociada con una estadística de interés sin hacer suposiciones fuertes sobre la distribución de los datos subyacentes.\n",
    "\n",
    "\n",
    "Para formar submuestras usaremos dt.sample(# muestras, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.Series([\n",
    "    10.7 ,  9.58,  7.74,  8.3 , 11.82,  9.74, 10.18,  8.43,  8.71,\n",
    "     6.84,  9.26, 11.61, 11.08,  8.94,  8.44, 10.41,  9.36, 10.85,\n",
    "    10.41,  8.37,  8.99, 10.17,  7.78, 10.79, 10.61, 10.87,  7.43,\n",
    "     8.44,  9.44,  8.26,  7.98, 11.27, 11.61,  9.84, 12.47,  7.8 ,\n",
    "    10.54,  8.99,  7.33,  8.55,  8.06, 10.62, 10.41,  9.29,  9.98,\n",
    "     9.46,  9.99,  8.62, 11.34, 11.21, 15.19, 20.85, 19.15, 19.01,\n",
    "    15.24, 16.66, 17.62, 18.22, 17.2 , 15.76, 16.89, 15.22, 18.7 ,\n",
    "    14.84, 14.88, 19.41, 18.54, 17.85, 18.31, 13.68, 18.46, 13.99,\n",
    "    16.38, 16.88, 17.82, 15.17, 15.16, 18.15, 15.08, 15.91, 16.82,\n",
    "    16.85, 18.04, 17.51, 18.44, 15.33, 16.07, 17.22, 15.9 , 18.03,\n",
    "    17.26, 17.6 , 16.77, 17.45, 13.73, 14.95, 15.57, 19.19, 14.39,\n",
    "    15.76])\n",
    "\n",
    "state = np.random.RandomState(12345)\n",
    "\n",
    "\n",
    "# Valores para el cuantil del 99% en la variable valores\n",
    "conf_int_values = []\n",
    "\n",
    "#Obteniendo el intervalo de confianza / Confidence interval del 99%\n",
    "for i in range(1000):\t\n",
    "\tsubsample = data.sample(frac=1, replace=True, random_state=state) #tambien se puede usar el parametro fraq=1 para especificar que queremos #la misma longitud de la base origina (100%)\n",
    "\tquantile = subsample.quantile(0.99)\n",
    "\tconf_int_values.append(quantile)\n",
    "\n",
    "# Con los datos obtenidos, crearemos una Serie y sacaremos el valor mayor y menor (percentiles)\n",
    "values = pd.Series(conf_int_values)\n",
    "lower = values.quantile(0.05)\n",
    "upper = values.quantile(0.95)\n",
    "\n",
    "confidence_interval =f'{lower:.2f}, {upper:.2f}'\n",
    "\n",
    "print(confidence_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping para el analisis de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# datos del grupo de control A\n",
    "samples_A = pd.Series([\n",
    "     98.24,  97.77,  95.56,  99.49, 101.4 , 105.35,  95.83,  93.02,\n",
    "    101.37,  95.66,  98.34, 100.75, 104.93,  97.  ,  95.46, 100.03,\n",
    "    102.34,  98.23,  97.05,  97.76,  98.63,  98.82,  99.51,  99.31,\n",
    "     98.58,  96.84,  93.71, 101.38, 100.6 , 103.68, 104.78, 101.51,\n",
    "    100.89, 102.27,  99.87,  94.83,  95.95, 105.2 ,  97.  ,  95.54,\n",
    "     98.38,  99.81, 103.34, 101.14, 102.19,  94.77,  94.74,  99.56,\n",
    "    102.  , 100.95, 102.19, 103.75, 103.65,  95.07, 103.53, 100.42,\n",
    "     98.09,  94.86, 101.47, 103.07, 100.15, 100.32, 100.89, 101.23,\n",
    "     95.95, 103.69, 100.09,  96.28,  96.11,  97.63,  99.45, 100.81,\n",
    "    102.18,  94.92,  98.89, 101.48, 101.29,  94.43, 101.55,  95.85,\n",
    "    100.16,  97.49, 105.17, 104.83, 101.9 , 100.56, 104.91,  94.17,\n",
    "    103.48, 100.55, 102.66, 100.62,  96.93, 102.67, 101.27,  98.56,\n",
    "    102.41, 100.69,  99.67, 100.99])\n",
    "\n",
    "# datos del grupo experimental B\n",
    "samples_B = pd.Series([\n",
    "    101.67, 102.27,  97.01, 103.46, 100.76, 101.19,  99.11,  97.59,\n",
    "    101.01, 101.45,  94.8 , 101.55,  96.38,  99.03, 102.83,  97.32,\n",
    "     98.25,  97.17, 101.1 , 102.57, 104.59, 105.63,  98.93, 103.87,\n",
    "     98.48, 101.14, 102.24,  98.55, 105.61, 100.06,  99.  , 102.53,\n",
    "    101.56, 102.68, 103.26,  96.62,  99.48, 107.6 ,  99.87, 103.58,\n",
    "    105.05, 105.69,  94.52,  99.51,  99.81,  99.44,  97.35, 102.97,\n",
    "     99.77,  99.59, 102.12, 104.29,  98.31,  98.83,  96.83,  99.2 ,\n",
    "     97.88, 102.34, 102.04,  99.88,  99.69, 103.43, 100.71,  92.71,\n",
    "     99.99,  99.39,  99.19,  99.29, 100.34, 101.08, 100.29,  93.83,\n",
    "    103.63,  98.88, 105.36, 101.82, 100.86, 100.75,  99.4 ,  95.37,\n",
    "    107.96,  97.69, 102.17,  99.41,  98.97,  97.96,  98.31,  97.09,\n",
    "    103.92, 100.98, 102.76,  98.24,  97.  ,  98.99, 103.54,  99.72,\n",
    "    101.62, 100.62, 102.79, 104.19])\n",
    "\n",
    "# diferencia real entre las medias de los grupos\n",
    "AB_difference = samples_B.mean() - samples_A.mean()\n",
    "print(\"Diferencia entre los importes promedios de compra:\", AB_difference)\n",
    "\n",
    "alpha = 0.05\n",
    "    \n",
    "state = np.random.RandomState(12345)\n",
    "\n",
    "bootstrap_samples = 1000\n",
    "count = 0\n",
    "\n",
    "for i in range(bootstrap_samples):\n",
    "    # concatena las muestras\n",
    "    united_samples = pd.concat([samples_A,samples_B])\n",
    "    \n",
    "    # crea una submuestra\n",
    "    subsample = united_samples.sample(frac=1, replace=True, random_state=state)\n",
    "    \n",
    "    # divide la submuestra por la mitad\n",
    "    subsample_A = subsample[:100]\n",
    "    subsample_B = subsample[100:]\n",
    "\n",
    "    # encuentra la diferencia entre las medias\n",
    "    bootstrap_difference = subsample_B.mean() - subsample_A.mean()\n",
    "    \n",
    "    # si la diferencia no es menor que la diferencia real, añade \"1\" al contador\n",
    "    if bootstrap_difference >= AB_difference:\n",
    "        count += 1\n",
    "\n",
    "# el valor p es igual al porcentaje de valores excedentes\n",
    "pvalue = 1. * count / bootstrap_samples\n",
    "print('p-value =', pvalue)\n",
    "print(count)\n",
    "\n",
    "if pvalue < alpha:\n",
    "    print(\"La hipótesis nula se rechaza, a saber, es probable que el importe promedio de las compras aumente\")\n",
    "else:\n",
    "    print(\"La hipótesis nula no se rechaza, a saber, es poco probable que el importe medio de las compras aumente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí coloco un ejemplo de como funcionan las series al momento de usar sus indices para realizar una busqueda dentro de otra serie. Aunque sus valores sean repetidos, la segunda serie los identificará ya que su busqueda la hará por el índice, no por el valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animales = pd.Series(['gato','araña','alacran','canguro'])\n",
    "patas = pd.Series([4,8,6,2])\n",
    "\n",
    "new_animales = animales.sample(frac=1, replace=True, random_state=1234)\n",
    "print(new_animales)\n",
    "patas_prob = patas[new_animales.index]\n",
    "\n",
    "\n",
    "patas_prob.quantile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo se coloca un uso completo para los quantiles y los sample, recordando que para sample podemos usar el parametro 'n' (en lugar de frac)  para especificar el número de muestras que queremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Abre los archivos\n",
    "# toma el índice “0” para convertir los datos a pd-Series\n",
    "target = pd.read_csv('/datasets/eng_target.csv')['0']\n",
    "probabilities = pd.read_csv('/datasets/eng_probabilites.csv')['0']\n",
    "\n",
    "\n",
    "#Llamado de la funcion\n",
    "def revenue(target, probabilities, count):\n",
    "    probs_sorted = probabilities.sort_values(ascending=False)\n",
    "    selected = target[probs_sorted.index][:count]\n",
    "    return 10 * selected.sum()\n",
    "\n",
    "#Parametro random state\n",
    "state = np.random.RandomState(12345)\n",
    "\n",
    "# Lista de valores que sera llenada con append.\n",
    "values = []\n",
    "\n",
    "# Iteracion para obtener el cuantil de ingresos del 1%\n",
    "for i in range(1000):\n",
    "    target_subsample = target.sample(n=25, replace=True ,random_state=state)\n",
    "    probs_subsample = probabilities[target_subsample.index]\n",
    "    values.append(revenue(target_subsample, probs_subsample, 10))\n",
    "\n",
    "values = pd.Series(values)\n",
    "lower = values.quantile(0.01)\n",
    "\n",
    "mean = values.mean()\n",
    "print(\"Ingresos promedio:\", mean)\n",
    "print(\"Cuantil del 1 %:\", lower)\n",
    "print(\"Cuantil del 1 %:\", lower2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación media de la evaluación del modelo: 0.7856284153005464\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "data = pd.read_csv('D:/Tripleten/datasets/heart.csv')\n",
    "features = data.drop(['target'], axis=1)\n",
    "target = data['target']\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "results = cross_val_score(model, features, target, cv=5)\n",
    "\n",
    "final_score = results.mean()\n",
    "\n",
    "print('Puntuación media de la evaluación del modelo:', final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, cross_val_score se utiliza para evaluar el rendimiento de un modelo dado, mientras que GridSearchCV se utiliza para encontrar los mejores hiperparámetros para un modelo mediante búsqueda exhaustiva. A menudo, GridSearchCV se utiliza en combinación con cross_val_score para seleccionar los mejores hiperparámetros y evaluar el rendimiento del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
