{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado Supervisado\n",
    "\n",
    "#### Arbol de decisíon\n",
    "\n",
    "A continuación vemos el primer elemento para aprender en modelados supervisados (son supervisados por que nosotros sabemos que resultados deben alcanzar).\n",
    "\n",
    "Los elementos que se usan en un arbol de decición son:\n",
    "\n",
    "- DecisionTreeClassifier() = Nuestras clase del modelo\n",
    "- model.fit (x,y) = para entrenar el modelo\n",
    "- model.predict (x) = para predecir el modelo\n",
    "- model.score(x) = para analizar la precision del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del mejor modelo en el conjunto de validacion: 0.891301000769823\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Importo el DataFrame\n",
    "df = pd.read_csv('D:/Tripleten/datasets/train_data.csv')\n",
    "\n",
    "# Creo una categorización por precios y la asigno a price_class\n",
    "df.loc[df['last_price'] > 5650000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 5650000, 'price_class'] = 0\n",
    "\n",
    "\n",
    "# Obtengo la base a entrenar y la base con los resultados esperados\n",
    "features = df.drop(['last_price', 'price_class'], axis=1)\n",
    "target = df['price_class']\n",
    "\n",
    "\n",
    "# Creo una iteración para buscar la mejor rama de acuerdo a su accuracy\n",
    "best_model = None\n",
    "best_result = 0\n",
    "for depth in range(1, 6):\n",
    "\tmodel = DecisionTreeClassifier(random_state=12345, max_depth= depth) # crea un modelo con la profundidad proporcionada\n",
    "\tmodel.fit(features, target) # entrena el modelo \n",
    "\tpredictions = model.predict(features) # obtén las predicciones del modelo\n",
    "\tresult = accuracy_score(target,predictions) # calcula la exactitud\n",
    "\tif result > best_result:\n",
    "\t\tbest_model = model\n",
    "\t\tbest_result = result\n",
    "        \n",
    "print(\"Exactitud del mejor modelo en el conjunto de validacion:\", best_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separar datos en dos conjuntos\n",
    "\n",
    "El conjunto de validación constituye el 25 % de los datos fuente. Entonces, ¿cómo debemos extraerlo?\n",
    "En sklearn hay una función llamada train_test_split, con la que se puede separar cualquier conjunto de datos en dos: entrenamiento y prueba. Pero nosotros vamos a usar esta función para obtener un conjunto de validación y uno de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4871, 13)\n",
      "(4871,)\n",
      "(1624, 13)\n",
      "(1624,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importo el DataFrame\n",
    "df = pd.read_csv('D:/Tripleten/datasets/train_data.csv')\n",
    "\n",
    "# Creo una categorización por precios y la asigno a price_class\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "# Divido en dos dataframes para tener un conjunto de validación\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Obtengo la base a entrenar y la base con los resultados esperados para mi primer conjunto de entrenamiento\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "\n",
    "# Obtengo que usaré para validar el primer conjunto. (un comparativo)\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class']\n",
    "\n",
    "#Primer conjunto con el 75% de los datos\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "\n",
    "#Segundo conjunto con el 25% de los datos\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo un conjunto de datos dividido una base muestra y una validación podemos iterar para encontrar un mejor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.8522167487684729\n",
      "max_depth = 2 : 0.8522167487684729\n",
      "max_depth = 3 : 0.8466748768472906\n",
      "max_depth = 4 : 0.8725369458128078\n",
      "max_depth = 5 : 0.8663793103448276\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('D:/Tripleten/datasets/train_data_us.csv')\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class']\n",
    "\n",
    "for i in range(1, 6):\n",
    "    model = DecisionTreeClassifier(max_depth=i, random_state=12345)\n",
    "    model.fit(features_train,target_train)\n",
    "    prediction = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, prediction)\n",
    "    print(\"max_depth =\", i, \": \", end='')\n",
    "    print(accuracy) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "87% de exactitud suena bien, pero podemos mejorarlo con un bosque aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bosque Aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con un nuevo algoritmo de aprendizaje llamado bosque aleatorio. Este algoritmo entrena una gran cantidad de árboles independientes y toma una decisión mediante el voto. Un bosque aleatorio ayuda a mejorar los resultados y a evitar el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importo el DataFrame\n",
    "df = pd.read_csv('/datasets/train_data_us.csv')\n",
    "\n",
    "# Creo una categorización por precios y la asigno a price_class\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "# Divido en dos dataframes para tener un conjunto de validación\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=54321) # segmenta el 25% de los datos para hacer el conjunto de validación\n",
    "\n",
    "# Obtengo la base a entrenar y la base con los resultados esperados para mi primer conjunto de entrenamiento\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "\n",
    "# Obtengo que usaré para validar el primer conjunto. (un comparativo)\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class']\n",
    "\n",
    "\n",
    "# Se genera una iteración para aplicar 10 arboles que nos mostrarán la mejor puntuación obtenida en las priebas y el número de bosques necesarios.\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 11): # selecciona el rango del hiperparámetro\n",
    "    model = RandomForestClassifier(random_state=54321, n_estimators=est) # configura el número de árboles\n",
    "    model.fit(features_train, target_train) # entrena el modelo en el conjunto de entrenamiento\n",
    "    score = model.score(features_valid,target_valid) # calcula la puntuación de accuracy en el conjunto de validación\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est \n",
    "                                   \n",
    "print(\"La exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}\".format(best_est, best_score))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
