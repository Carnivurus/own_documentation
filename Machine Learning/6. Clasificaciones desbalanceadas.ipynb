{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobremuestreo\n",
    "\n",
    "El sobremuestreo, en el contexto del aprendizaje automático y especialmente en el manejo de conjuntos de datos desbalanceados, es una técnica que se utiliza para aumentar el número de muestras en la clase minoritaria (la clase menos representada) con el fin de equilibrar mejor la distribución de clases en el conjunto de datos.\n",
    "\n",
    "El sobremuestreo se realiza en varios pasos:\n",
    "- Dividir el conjunto de datos de entrenamiento en observaciones negativas y positivas;\n",
    "- Duplicar las observaciones positivas (las que tienen ocurrencias raras) varias veces;\n",
    "- Crear una nueva muestra de entrenamiento basada en los datos obtenidos;\n",
    "- Barajar los datos: preguntas idénticas que se suceden no ayudarán al entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.13688212927756654\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Importamos el conjunto de datos\n",
    "\n",
    "data = pd.read_csv('D:/Tripleten/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "# Definimos el objetivo y el los elementos para entrenar\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "\n",
    "# Dividimos el conjunto en training y validación\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# Declaramos una funcion para obtener el sobremuestreo del conjunto de entrenamiento\n",
    "# Separamos los elementos en los cuales su target tiene 0 y 1\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    # Concatenamos no sin antes exponenciar los resultados para tener un conjunto mas robusto.\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# Llamamos la funcion y recibimos dos variables\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n",
    "\n",
    "# Entrenamos nuestro modelo\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled,target_upsampled)\n",
    "\n",
    "#Predecimos y entregamos el resultado.\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
