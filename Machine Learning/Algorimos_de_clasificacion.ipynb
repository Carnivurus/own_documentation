{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado Supervisado\n",
    "\n",
    "## Arbol de decisíon\n",
    "\n",
    "A continuación vemos el primer elemento para aprender en modelados supervisados (son supervisados por que nosotros sabemos que resultados deben alcanzar).\n",
    "\n",
    "Los elementos que se usan en un arbol de decición son:\n",
    "\n",
    "- DecisionTreeClassifier() = Nuestras clase del modelo\n",
    "- model.fit (x,y) = para entrenar el modelo\n",
    "- model.predict (x) = para predecir el modelo\n",
    "- model.score(x) = para analizar la precision del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del mejor modelo en el conjunto de validacion: 0.891301000769823\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Importo el DataFrame\n",
    "df = pd.read_csv('D:/Tripleten/datasets/train_data.csv')\n",
    "\n",
    "# Creo una categorización por precios y la asigno a price_class\n",
    "df.loc[df['last_price'] > 5650000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 5650000, 'price_class'] = 0\n",
    "\n",
    "\n",
    "# Obtengo la base a entrenar y la base con los resultados esperados\n",
    "features = df.drop(['last_price', 'price_class'], axis=1)\n",
    "target = df['price_class']\n",
    "\n",
    "\n",
    "# Creo una iteración para buscar la mejor rama de acuerdo a su accuracy\n",
    "best_model = None\n",
    "best_result = 0\n",
    "for depth in range(1, 6):\n",
    "\tmodel = DecisionTreeClassifier(random_state=12345, max_depth= depth) # crea un modelo con la profundidad proporcionada\n",
    "\tmodel.fit(features, target) # entrena el modelo \n",
    "\tpredictions = model.predict(features) # obtén las predicciones del modelo\n",
    "\tresult = accuracy_score(target,predictions) # calcula la exactitud\n",
    "\tif result > best_result:\n",
    "\t\tbest_model = model\n",
    "\t\tbest_result = result\n",
    "        \n",
    "print(\"Exactitud del mejor modelo en el conjunto de validacion:\", best_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separar datos en dos conjuntos\n",
    "\n",
    "El conjunto de validación constituye el 25 % de los datos fuente. Entonces, ¿cómo debemos extraerlo?\n",
    "En sklearn hay una función llamada train_test_split, con la que se puede separar cualquier conjunto de datos en dos: entrenamiento y prueba. Pero nosotros vamos a usar esta función para obtener un conjunto de validación y uno de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4871, 13)\n",
      "(4871,)\n",
      "(1624, 13)\n",
      "(1624,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importo el DataFrame\n",
    "df = pd.read_csv('D:/Tripleten/datasets/train_data.csv')\n",
    "\n",
    "# Creo una categorización por precios y la asigno a price_class\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "# Divido en dos dataframes para tener un conjunto de validación\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Obtengo la base a entrenar y la base con los resultados esperados para mi primer conjunto de entrenamiento\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "\n",
    "# Obtengo que usaré para validar el primer conjunto. (un comparativo)\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class']\n",
    "\n",
    "#Primer conjunto con el 75% de los datos\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "\n",
    "#Segundo conjunto con el 25% de los datos\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo un conjunto de datos dividido una base muestra y una validación podemos iterar para encontrar un mejor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.8522167487684729\n",
      "max_depth = 2 : 0.8522167487684729\n",
      "max_depth = 3 : 0.8466748768472906\n",
      "max_depth = 4 : 0.8725369458128078\n",
      "max_depth = 5 : 0.8663793103448276\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('D:/Tripleten/datasets/train_data_us.csv')\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class']\n",
    "\n",
    "for i in range(1, 6):\n",
    "    model = DecisionTreeClassifier(max_depth=i, random_state=12345)\n",
    "    model.fit(features_train,target_train)\n",
    "    prediction = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, prediction)\n",
    "    print(\"max_depth =\", i, \": \", end='')\n",
    "    print(accuracy) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "87% de exactitud suena bien, pero podemos mejorarlo con un bosque aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bosque Aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con un nuevo algoritmo de aprendizaje llamado bosque aleatorio. Este algoritmo entrena una gran cantidad de árboles independientes y toma una decisión mediante el voto. Un bosque aleatorio ayuda a mejorar los resultados y a evitar el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de validación (n_estimators = 10): 0.8860837438423645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importo el DataFrame\n",
    "df = pd.read_csv('D:/Tripleten/datasets/train_data_us.csv')\n",
    "\n",
    "# Creo una categorización por precios y la asigno a price_class\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "# Divido en dos dataframes para tener un conjunto de validación\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=54321) # segmenta el 25% de los datos para hacer el conjunto de validación\n",
    "\n",
    "# Obtengo la base a entrenar y la base con los resultados esperados para mi primer conjunto de entrenamiento\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "\n",
    "# Obtengo que usaré para validar el primer conjunto. (un comparativo)\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class']\n",
    "\n",
    "\n",
    "# Se genera una iteración para aplicar 10 arboles que nos mostrarán la mejor puntuación obtenida en las priebas y el número de bosques necesarios.\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 11): # selecciona el rango del hiperparámetro\n",
    "    model = RandomForestClassifier(random_state=54321, n_estimators=est) # configura el número de árboles\n",
    "    model.fit(features_train, target_train) # entrena el modelo en el conjunto de entrenamiento\n",
    "    score = model.score(features_valid,target_valid) # calcula la puntuación de accuracy en el conjunto de validación\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est \n",
    "                                   \n",
    "print(\"La exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}\".format(best_est, best_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion logística\n",
    "\n",
    "El aprendizaje de algoritmos no solo requiere árboles de decisión, sino también otros enfoques para realizar tareas de clasificación.\n",
    "\n",
    "LogisticRegression es un algoritmo de aprendizaje automático supervisado utilizado principalmente para problemas de clasificación binaria, A pesar de su nombre, LogisticRegression no se utiliza para problemas de regresión, sino para problemas de clasificación.\n",
    "\n",
    "El objetivo de LogisticRegression es predecir la probabilidad de que una observación pertenezca a una de las dos clases (en el caso de clasificación binaria) o a una de múltiples clases (en el caso de clasificación multiclase). La predicción se realiza mediante una función logística (también conocida como función sigmoide), que transforma la salida del modelo lineal en un valor entre 0 y 1, que puede interpretarse como la probabilidad de pertenencia a una clase.\n",
    "\n",
    "Para ejecutarlo en python debemos de hacerlo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8764114144939438\n",
      "0.8866995073891626\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importo el DataFrame\n",
    "df = pd.read_csv('D:/Tripleten/datasets/train_data_us.csv')\n",
    "\n",
    "# Preparo la data para el entrenamiento, obteniendo el resultado esperado ('clasificación') y separandolo del dataframe para el entrenamiento\n",
    "df['price_class'] = df['last_price'].apply(lambda x: 1 if x > 113000 else 0)\n",
    "\n",
    "# Mando  llamar train_test_split para tener una base y una validación\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=54321)\n",
    "\n",
    "# Separamos los datos por analizar (features) de los resultados (target) para la base de entrenamiento y la validación\n",
    "train_features = df_train.drop(columns=['last_price','price_class'])\n",
    "train_target = df_train['price_class']\n",
    "\n",
    "df_valid_features = df_valid.drop(columns=['last_price','price_class'])\n",
    "df_valid_target = df_valid['price_class']\n",
    "\n",
    "# Llamamos nuestro modelo con sus respectivos hiperparametros y los entrenamos\n",
    "model = LogisticRegression(random_state=54321, solver='liblinear') ####\n",
    "model.fit(train_features, train_target)\n",
    "\n",
    "# Obtenemosel score de cada base\n",
    "target_score = model.score(train_features,train_target)\n",
    "valid_score = model.score(df_valid_features,df_valid_target)\n",
    "\n",
    "print(target_score)\n",
    "print(valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, cada algoritmo tiene sus ventajas y lo podemos expresar de la siguiente forma:\n",
    "\n",
    "| Nombre             | Precisión | Velocidad |\n",
    "|--------------------|-----------|-----------|\n",
    "| árbol de decisión | Bajo      | Alto      |\n",
    "| bosque aleatorio   | Alto      | Bajo      |\n",
    "| regresión logística| Medio     | Bajo      |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
